{"cells":[{"cell_type":"markdown","metadata":{"id":"EYYak4lmL7q8"},"source":["Note: Google collab doesn't support OpenCV. So please open it in Jupyter notebook or the local machine instead ðŸ˜€."]},{"cell_type":"markdown","metadata":{"id":"L7HpFx_v3GlK"},"source":["#Install modules\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQCu17SL1JbW"},"outputs":[],"source":["!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"mUCM7AiM0qSp"},"source":["#Import modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZvzH9gN4uO0"},"outputs":[],"source":["import cv2\n","import os\n","import numpy as np\n","import keras\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.applications import VGG16\n","from keras import backend as K\n","from keras.models import Model, Sequential\n","from keras.layers import Input, Dense, Activation, LSTM\n","import h5py"]},{"cell_type":"markdown","metadata":{"id":"SGuHoYa91UrZ"},"source":["#Initial variables\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_odMJZYI4uO3"},"outputs":[],"source":["DIR_TR = \"dataset/Train/\"\n","DIR_TE = \"dataset/Test/\"\n","DIR_VA = \"dataset/Valid/\"\n","\n","# Frame size  \n","IMG_SIZE = 224\n","IMG_SIZE_TUPLE = (IMG_SIZE, IMG_SIZE)\n","\n","# Number of channels (RGB)\n","NUM_CHANNELS = 3\n","# Flat frame size\n","IMG_SIZE_FLAT = IMG_SIZE**2 * NUM_CHANNELS\n","\n","# Number of classes for classification (Violence-No Violence)\n","NUM_CLASSES = 2\n","CLASSES_LIST = ['NonViolence', 'Violence']\n","assert len(CLASSES_LIST) == NUM_CLASSES\n","\n","SEQUENCE_LENGTH = 20"]},{"cell_type":"markdown","metadata":{"id":"IW52o0BB1yGt"},"source":["#VGG16 Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6081,"status":"ok","timestamp":1655104799552,"user":{"displayName":"à¸Šà¸´à¸™à¸§à¸±à¸•à¸£ à¸™à¸²à¹„à¸Šà¸¢à¸˜à¸‡","userId":"10452193718542966036"},"user_tz":-420},"id":"nM5y_QMq4uO5","outputId":"158e9fca-a1e5-489c-d618-be6614c6828b"},"outputs":[],"source":["image_model = VGG16(include_top=True, weights='imagenet')\n","image_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1655104799552,"user":{"displayName":"à¸Šà¸´à¸™à¸§à¸±à¸•à¸£ à¸™à¸²à¹„à¸Šà¸¢à¸˜à¸‡","userId":"10452193718542966036"},"user_tz":-420},"id":"z_roX6en4uO7","outputId":"a0123c32-f5a6-4beb-d56f-9b964736abfd"},"outputs":[],"source":["transfer_layer = image_model.get_layer('fc2')\n","image_model_transfer = Model(inputs=image_model.input,\n","                             outputs=transfer_layer.output)"]},{"cell_type":"markdown","metadata":{"id":"W6ESgRLM1igz"},"source":["#Frame extraction function"]},{"cell_type":"markdown","metadata":{"id":"C60BR9lT4xlz"},"source":["## Function"]},{"cell_type":"markdown","metadata":{"id":"rRyzInZ8Nv_0"},"source":["Get array of each frame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2fS-9egP4uO4"},"outputs":[],"source":["\n","def get_frames(vid_path):\n","    cap = cv2.VideoCapture(vid_path)\n","    total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT) \n","    split_size = int(min(5, max(total_frames // SEQUENCE_LENGTH, 1)))\n","    chunk_size = total_frames / split_size\n","    skip_frame = max(1, chunk_size // SEQUENCE_LENGTH)\n","    \n","    for c in range(split_size):\n","        initial_frame = SEQUENCE_LENGTH * c * skip_frame\n","        \n","        frames_list = []\n","        for i in range(SEQUENCE_LENGTH):\n","            cap.set(cv2.CAP_PROP_POS_FRAMES, (i * skip_frame) + initial_frame)\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","            \n","            RGB_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","            res = cv2.resize(RGB_img, \n","                             dsize=IMG_SIZE_TUPLE,\n","                             interpolation=cv2.INTER_CUBIC)\n","            \n","            frames_list.append(res)\n","        result = np.array(frames_list)\n","        result = (result / 255).astype(np.float16)\n","        \n","        yield result\n","        "]},{"cell_type":"markdown","metadata":{"id":"4rmzysvqNxLb"},"source":["Extract features each frame from video"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VuIv-yZ64uO8"},"outputs":[],"source":["def extracted_features(vid_path):\n","    gen = get_frames(vid_path)\n","    for chunk in gen:\n","        shape = (SEQUENCE_LENGTH, 4096)\n","        transfer_values = np.zeros(shape=shape, dtype=np.float16)\n","        transfer_values = image_model_transfer.predict(chunk)\n","        \n","        yield transfer_values\n","    "]},{"cell_type":"markdown","metadata":{"id":"63H6kq4JN6bt"},"source":["Create dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dTS1Qr3R4uO9"},"outputs":[],"source":["def create_dataset(dataset_dir):\n","    class_dataset_dir = os.listdir(dataset_dir)\n","    features = []\n","    labels = []\n","    \n","    \n","    for dir in class_dataset_dir:\n","        videos_list = os.listdir(os.path.join(dataset_dir, dir))\n","        count = 0\n","        for vid in videos_list:\n","            gen_path = os.path.join(dataset_dir, dir, vid)\n","            gen = extracted_features(gen_path)\n","            for chunk in gen:\n","                features.append(chunk)\n","                if dir == CLASSES_LIST[0]:\n","                    labels.append([1, 0])\n","                elif dir == CLASSES_LIST[1]:\n","                    labels.append([0, 1])\n","            count += 1\n","            \n","            print(dir, '{:.2f}%'.format((count /len(videos_list))*100))\n","    return features, labels"]},{"cell_type":"markdown","metadata":{"id":"uuhfr6dS163I"},"source":["##Create dataset for video"]},{"cell_type":"markdown","metadata":{"id":"okGYhtx940P2"},"source":["Note: Please skip this section if you already save the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bqBqBvp24uO9","outputId":"ce8df721-b6c5-4dcb-8ad3-7a2ee92bbbe3"},"outputs":[],"source":["features_tr, labels_tr = create_dataset(DIR_TR)\n","features_te, labels_te = create_dataset(DIR_TE)\n","features_va, labels_va = create_dataset(DIR_VA)"]},{"cell_type":"markdown","metadata":{"id":"0a9xD8Uo2Kk2"},"source":["##Write and load dataset"]},{"cell_type":"markdown","metadata":{"id":"7O7b43eD5CFQ"},"source":["After you finish the create dataset section. Uncomment this below code to save the dataset and when you've done, Comment it again to make sure you won't overwrite it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X-u_VylM4uO_"},"outputs":[],"source":["# with h5py.File('features_labels/datav6.h5', mode='w') as file:\n","#     file.create_dataset('X_tr', data=features_tr)\n","#     file.create_dataset('X_te', data=features_te)\n","#     file.create_dataset('X_va', data=features_va)\n","    \n","#     file.create_dataset('y_tr', data=labels_tr)\n","#     file.create_dataset('y_te', data=labels_te)\n","#     file.create_dataset('y_va', data=labels_va)"]},{"cell_type":"markdown","metadata":{"id":"-FIdiHdB5wm2"},"source":["Load the dataset from hdf5 file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CfH-6WIJ4uPA"},"outputs":[],"source":["with h5py.File('features_labels/datav6.h5', mode='r') as file:\n","    X_tr = file['X_tr'][:]\n","    X_te = file['X_te'][:]\n","    X_va = file['X_va'][:]\n","    \n","    y_tr = file['y_tr'][:]\n","    y_te = file['y_te'][:]\n","    y_va = file['y_va'][:]"]},{"cell_type":"markdown","metadata":{"id":"hipjZvk-2ZAC"},"source":["##Check data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1655104818688,"user":{"displayName":"à¸Šà¸´à¸™à¸§à¸±à¸•à¸£ à¸™à¸²à¹„à¸Šà¸¢à¸˜à¸‡","userId":"10452193718542966036"},"user_tz":-420},"id":"IOhAJ4N45zVs","outputId":"983c332a-47cb-416c-bdf6-27a4a7defe19"},"outputs":[],"source":["print(\"Train features\", len(X_tr))\n","print(\"Test features\", len(X_te))\n","print(\"Validation features\", len(X_va))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"414FeY_K54Gy"},"outputs":[],"source":["print(\"Train label\", len(y_tr))\n","print(\"Test label\", len(y_te))\n","print(\"Validation label\", len(y_va))"]},{"cell_type":"markdown","metadata":{"id":"cWywynk42gMd"},"source":["#LSTM model"]},{"cell_type":"markdown","metadata":{"id":"uk2CPIey2uxw"},"source":["##Create model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Np_Fohrf4uPA"},"outputs":[],"source":["chunk_size = 4096\n","n_chunks = SEQUENCE_LENGTH\n","rnn_size = 512\n","\n","model = Sequential()\n","model.add(LSTM(rnn_size, input_shape=(n_chunks, chunk_size)))\n","model.add(Dense(1024))\n","model.add(Activation('relu'))\n","model.add(Dense(50))\n","model.add(Activation('sigmoid'))\n","model.add(Dense(2))\n","model.add(Activation('softmax'))\n"]},{"cell_type":"markdown","metadata":{"id":"rjw0Y4Hc2zPb"},"source":["##Train model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":171588,"status":"ok","timestamp":1655105682808,"user":{"displayName":"à¸Šà¸´à¸™à¸§à¸±à¸•à¸£ à¸™à¸²à¹„à¸Šà¸¢à¸˜à¸‡","userId":"10452193718542966036"},"user_tz":-420},"id":"RwmKCz_C4uPB","outputId":"df0155d1-0946-4bd3-9e24-792ac3c76448"},"outputs":[],"source":["from keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","epoch = 200\n","batchS = 500\n","\n","early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 15, mode = 'min', restore_best_weights = True)\n","\n","opt = Adam(learning_rate=0.001)\n","model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])\n","history = model.fit(x=np.array(X_tr), y=np.array(y_tr), epochs=epoch,\n","                    validation_data=(np.array(X_va), np.array(y_va)),\n","                    shuffle=True,\n","                    batch_size=batchS, verbose=2,\n","                    callbacks=[early_stopping_callback])"]},{"cell_type":"markdown","metadata":{"id":"vIEqtPFt245s"},"source":["##Evaluate model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21748,"status":"ok","timestamp":1655105717939,"user":{"displayName":"à¸Šà¸´à¸™à¸§à¸±à¸•à¸£ à¸™à¸²à¹„à¸Šà¸¢à¸˜à¸‡","userId":"10452193718542966036"},"user_tz":-420},"id":"mD99rIja4uPB","outputId":"38c637be-04b4-49fa-d7f1-d2d96ed9e9f9"},"outputs":[],"source":["result = model.evaluate(np.array(X_te), np.array(y_te))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":424,"status":"ok","timestamp":1655104549612,"user":{"displayName":"à¸Šà¸´à¸™à¸§à¸±à¸•à¸£ à¸™à¸²à¹„à¸Šà¸¢à¸˜à¸‡","userId":"10452193718542966036"},"user_tz":-420},"id":"AYRx_fEa4uPB","outputId":"653ee12e-c669-4092-bb94-7e14d18ada6d"},"outputs":[],"source":["for name, value in zip(model.metrics_names, result):\n","    print(name, value)\n"]},{"cell_type":"markdown","metadata":{"id":"ZR8mWhJB29Kk"},"source":["##Plot graph."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":646},"executionInfo":{"elapsed":1029,"status":"ok","timestamp":1655105735924,"user":{"displayName":"à¸Šà¸´à¸™à¸§à¸±à¸•à¸£ à¸™à¸²à¹„à¸Šà¸¢à¸˜à¸‡","userId":"10452193718542966036"},"user_tz":-420},"id":"IcxmQpQq4uPC","outputId":"4414cc9b-ca33-49f9-df9d-339b6b8d14d8"},"outputs":[],"source":["plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.savefig('destination_path.eps', format='eps', dpi=1000)\n","plt.show()\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.savefig('destination_path1.eps', format='eps', dpi=1000)\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"mVopoxc73AM2"},"source":["##Save model and save weights."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BFQSVBnN9tje"},"outputs":[],"source":["model.save('model/vggLSTM/modelv4_2.h5')\n","model.save_weights('model/vggLSTM/model_weightsv4_2.h5')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["C60BR9lT4xlz","uk2CPIey2uxw","rjw0Y4Hc2zPb","ZR8mWhJB29Kk","mVopoxc73AM2"],"name":"Violence Detection.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3.10.4 ('violencedetection')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"8e7fdd385a006bab1d54cce523f040101c70cd6998bbc817cbd96698aaa7d552"}}},"nbformat":4,"nbformat_minor":0}
